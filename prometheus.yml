# Configuration file for prometheus data source
global:
  # Default scrape and evaluation interval is every minute.
  scrape_interval: 15s
  evaluation_interval: 15s

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  - 'prometheus.rules.yml'

# Define endpoints to scrape, for collection and monitoring of metrics of targets.
# Metrics_path defaults to '/metrics' and scheme defaults to 'http'.
scrape_configs:
  # Job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: "prometheus"

    # Override the global default and scrape targets from this job every 5 seconds.
    scrape_interval: 5s

    # Prometheus is running within its own container, so it can access its own services using localhost.
    # In this context, localhost means "inside the Prometheus container."
    # Prometheus is running within its own container, so it can access its own services using localhost.
    static_configs:
      - targets: ["prometheus:9090"]

  # Scrape configurations for monitoring sample targets with Node Exporter.
  - job_name: 'node_exporter'

    # Override the global default and scrape targets from this job every 5 seconds.
    scrape_interval: 5s

    # Port 9100 is the default port Node Exporter uses to expose metrics.
    # When each Node Exporter container is running in its own separate network namespace, use IP address.
    # When running on the same network as other containers, their service names can be used.
    static_configs:
      - targets: ['node_exporter_1:9100', 'node_exporter_2:9100', 'node_exporter_3:9100']
        labels:
          group: 'production'