# Configuration file for prometheus data source
global:
  # Default scrape and evaluation interval is every minute.
  scrape_interval: 15s
  evaluation_interval: 15s

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  - 'prometheus.rules.yml'

# Define endpoints to scrape, for collection and monitoring of metrics of targets.
# Metrics_path defaults to '/metrics' and scheme defaults to 'http'.
scrape_configs:
  # Job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: "prometheus"

    # Override the global default and scrape targets from this job every 5 seconds.
    scrape_interval: 5s

    # Prometheus is running within its own container, so it can access its own services using localhost.
    # In this context, localhost means "inside the Prometheus container."
    # Prometheus is running within its own container, so it can access its own services using localhost.
    static_configs:
      - targets: ["localhost:9090"]

  # Scrape configurations for monitoring sample targets with Node Exporter.
  - job_name: 'node_exporter'

    # Override the global default and scrape targets from this job every 5 seconds.
    scrape_interval: 5s

    # Port 9100 is the default port Node Exporter uses to expose metrics.
    # Each Node Exporter container is running in its own separate network namespace.
    # To access services running on the host or another container, you generally need to use the host's IP address.
    static_configs:
      - targets: ['172.17.0.6:9100', '172.17.0.7:9100']
        labels:
          group: 'production'

      - targets: ['172.17.0.8:9100']
        labels:
          group: 'testing'